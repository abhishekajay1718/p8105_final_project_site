---
title: "tentative report"
output:
  github_document
---

Motivation: Provide an overview of the project goals and motivation.

Related work: Anything that inspired you, such as a paper, a web site, or something we discussed in class.

Initial questions: What questions are you trying to answer? How did these questions evolve over the course of the project? What new questions did you consider in the course of your analysis?

Data: Source, scraping method, cleaning, etc.

Exploratory analysis: Visualizations, summaries, and exploratory statistical analyses. Justify the steps you took, and show any major changes to your ideas.

Additional analysis: If you undertake formal statistical analyses, describe these in detail

Discussion: What were your findings? Are they what you expect? What insights into the data can you make?

###Motivation:

A major concern in emergency medical services (EMS) planning has been the need to minimize response time to better patient outcome, translated by some EMS operations into a goal of a response time of 8 minutes or less for advanced life support (ALS) units responding to life-threatening events. An exploratory analysis suggested there may be a small beneficial effect of response â‰¤7 minutes 59 seconds for those who survived to become an inpatient. More information on this can be found [here](https://www.ncbi.nlm.nih.gov/pubmed/11927452) and [here](https://www.ncbi.nlm.nih.gov/pubmed/22026820)

Due to its large population, New York City requires a powerful, quick, well-equipped and effective Emergency Medical Service System. Hence, we decided to analyse the EMS response time in New York City in the year 2017 with respect to weather and street blockage so as to improve it.

### Initial questions: 
We tried to answer the factors assoicated with EMS response time. We assumed rainy or snowy conditions, season and hour of the day will affect the response time. 


### Data Source

<a href = "https://europepmc.org/articles/pmc32251">
Effect of reducing ambulance response times on deaths from out of hospital cardiac arrest: cohort study</a>

<a href = "https://www.ncbi.nlm.nih.gov/pubmed/22026820">Emergency medical services response time and mortality in an urban setting.</a>

<a href = "https://www.ncbi.nlm.nih.gov/pubmed/29381111">Neighborhood Poverty and 9-1-1 Ambulance Response Time.</a>

### Exploratory analysis: 

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(xml2)
library(rvest)
library(rnoaa)
library(knitr)
library(patchwork)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

theme_set(theme_bw())
```

### Step 1: Data preparation
1. Incident data (response from Fire company)
```{r }
incident_dat_2017 <-
  read_csv('data/Incidents_Responded_to_by_Fire_Companies.csv',
  col_types = "cicccicciccccccccccciccccccc") %>%
  janitor::clean_names() %>%
  #recode date/time
  mutate(incident_date_time = mdy_hms(incident_date_time),
         arrival_date_time = mdy_hms(arrival_date_time)) %>%
  #select year 2017
  filter(year(incident_date_time) == 2017,
         incident_type_desc == "300 - Rescue, EMS incident, other") %>%
  select(im_incident_key, incident_date_time, arrival_date_time,
         street_highway:borough_desc) %>%
  na.omit() %>%

  # Added response time(minute) variable
  # mutate(response_time = arrival_date_time - incident_date_time) %>%
  mutate(response_time = difftime(arrival_date_time, incident_date_time, units = 'mins'),
  # Added hour variable
  hour = hour(incident_date_time),
  date = date(incident_date_time),
  # Added incident_month and incident_day variables from incident_date_time
  incident_date = as.Date(incident_date_time)) %>%
  separate(incident_date,
           into = c("incident_year", "incident_month", "incident_day"),
           sep = "-") %>%
  select(-incident_year) %>%
  mutate(incident_month = as.numeric(incident_month),
         incident_day = as.numeric(incident_day),
         zip_code = as.numeric(zip_code))

save(incident_dat_2017, file = "data/incident_dat_2017.RData")
```

2. Neighborhood variable (by zipcode) dataset
```{r fig.height = 8}
url = "https://www.health.ny.gov/statistics/cancer/registry/appendix/neighborhoods.htm?fbclid=IwAR3N4VlKC1OehRZyEuDYPEAE7AFAEXXIRC11seIBKxA-0fd3g4hL0QvnV20"

xml = read_html(url)

zip_code_table = (xml %>% html_nodes(css = "table")) %>% 
  .[[1]] %>%
  html_table() %>% 
  janitor::clean_names() %>%  
  select(neighborhood, zip_codes) %>% 
  separate(zip_codes, c("a", "b", "c", "d", "e", "f", "g", "h", "i"), 
           sep = ",") %>% 
  gather(key = to_remove, value = zip_code, a:i) %>% 
  select(-to_remove) %>% 
  na.omit() %>% 
  distinct() %>% 
  mutate(zip_code = as.numeric(zip_code))

save(zip_code_table, file = "data/zipcode.RData")
```

3. Add weather-related dataset
```{r}
library(rnoaa)

nyc_weather_2017 = 
  rnoaa::meteo_pull_monitors("USW00094728", 
                             var = c("PRCP", "TMIN", "TMAX", "SNOW", "SNWD"), 
                             date_min = "2017-01-01", 
                             date_max = "2017-12-31"
                             ) %>% 
  mutate(tmin = tmin/10, tmax = tmax/10, prcp = prcp/10) %>% 
  select(-id)

save(nyc_weather_2017, file = "data/nyc_weather_2017.RData")
```

4. Merge first three for final dataset

```{r merge}
# incident_dat_2017 
finaldat =  
  left_join(incident_dat_2017, zip_code_table, by = "zip_code") %>% 
  inner_join(., nyc_weather_2017, by = "date") %>% 
  mutate(response_time = as.numeric(response_time))

save(finaldat, file = "data/finaldat.RData")

load('data/finaldat.RData')
```

Given that data of response time is right skewed, for visulization, we took a mean of response time as our outcome for exploratory analysis And then performed exploratory data analysis. 


### Step 2: Initial analysis (obsolete)
#### Step 2-1: EDA

1. Hourly trend of response time
```{r}
finaldat %>%
  group_by(hour) %>% 
  ggplot(aes(x = hour, y = response_time)) + 
  geom_smooth(se = FALSE) 
```

2. Response time in rainy and snowy days
```{r}
finaldat %>% 
  mutate(prcp = prcp > 0) %>%
  group_by(date, prcp) %>% 
  summarise(mean_resp_time = mean(response_time)) %>% 
  ggplot(aes(x = prcp, y = mean_resp_time)) +
  geom_violin(aes(fill = factor(prcp)), alpha = .5) +
  stat_summary(fun.y = mean, geom = "point", size = 4, color = "blue") +
  labs(
    title = "Mean Response time in rainy conditions",
    x = "Precipitation",
    y = "Response time"
  ) +
  viridis::scale_fill_viridis(
    name = "Precipitation",
    discrete = TRUE) +
  theme(plot.title = element_text(size = 12),
        strip.background = element_rect(fill = "black"),
        strip.text = element_text(color = "white", face = "bold"),
        legend.position = "None") 

finaldat %>% 
  mutate(snow = snow > 0) %>%
  group_by(date, snow) %>% 
  summarise(mean_resp_time = mean(response_time)) %>% 
  ggplot(aes(x = snow, y = mean_resp_time)) +
  geom_violin(aes(fill = factor(snow)), alpha = .5) +
  stat_summary(fun.y = mean, geom = "point", size = 4, color = "blue") +
  labs(
    title = "Mean response time in snowy conditions",
    y = "Mean response time",
    x = "Snow"
  ) +
  viridis::scale_fill_viridis(
    name = "Snow",
    discrete = TRUE) +
  theme(plot.title = element_text(size = 12),
        strip.background = element_rect(fill = "black"),
        strip.text = element_text(color = "white", face = "bold"),
        legend.position = "None") 
```

We showed some trends by hour of the day and by snowy conditions. Based on this result, we fit linear regression. 

#### Step 2-2: Linear regression 
1. hour of the day vs response time 

```{r}
fit_hour = lm(response_time ~ hour, data = finaldat)
fit_hour %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Ho: different hour of the day makes no difference in logs response time.
p-value: very small.
conclusion: There is a difference of log response time in different time/hour of the day.

2. snow & prcp vs response time ----- linear regression
```{r}
fit_snow = lm(response_time~snow, data = finaldat)
fit_snow %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

fit_prcp = lm(response_time~prcp, data = finaldat)
fit_prcp %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

H0: There is no correlation between snow and log_response_time
p-value: very small
estimate: positive
conclusion: There is a positive correlation between snow and log response time. 
3. MLR based on snow, prcp, tmax, tmin(factors of nature environment) in different hour of the day
```{r}
fit_mlr = lm(response_time~snow + prcp + tmax + tmin, data = finaldat)

fit_mlr %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

Even though we could get the statistically significant results with p-values less than 0.05, the estimates are too small so explanations from this was not meaningful. 

### Step 3: final analysis
#### Step 3-1: Modify variables 
Next, we categorized explanatory variables since we wanted to show the change of response time by the trend of precipitation, snow, season and time rather than by detailed amount of precipitation and snow or specific time. With these modified variables, we performed exploratory data analysis.

```{r finaldata, include = FALSE}
finaldat = 
  finaldat %>%
  mutate(season = 
           ifelse(incident_month %in% 9:11, "Fall",
           ifelse(incident_month %in% c(12,1,2), "Winter",
           ifelse(incident_month %in% 3:5, "Spring", "Summer"))), 
         hour_of_day = 
           ifelse(hour %in% 6:11, "morning",
           ifelse(hour %in% 12:17, "afternoon",
           ifelse(hour %in% 18:23, "night","dawn"))), 
         over_8min = ifelse(response_time > 8, "8min+", "8min-"),
         prcp_ctg = 
           if_else(prcp == 0, "no_prcp",
           if_else((prcp > 0 & prcp <= 25), "low", "high")),
         snow_ctg = 
           if_else(snow == 0, "no_snow",
           if_else((snow > 0 & snow <= 50), "low", "high")),
         over_8min = fct_relevel(over_8min, "8min-")) 
```

#### Step 3-2:EDA

1. precipitation and snow
```{r}
prcp_eda =
  finaldat %>% 
  mutate(prcp_ctg = fct_relevel(prcp_ctg, c("no_prcp", "low", "high"))) %>%   group_by(date, prcp_ctg) %>% 
  summarise(mean_resp_time = mean(response_time)) %>% 
  ggplot(aes(x = prcp_ctg, y = mean_resp_time)) +
  geom_violin(aes(fill = prcp_ctg), alpha = .3) +
  stat_summary(fun.y = mean, geom = "point", size = 2, color = "blue") +
  labs(
    title = "Rainy conditions",
    y = "Mean response time(min)",
    x = " "
  ) +
  scale_x_discrete(labels = c("0(mm)", "0-25(mm)", "25(mm)+")) +
  viridis::scale_fill_viridis(
    name = "Precipitation",
    discrete = TRUE) +
  theme(plot.title = element_text(size = 12),
        axis.title.y = element_text(size = 8),
        axis.text.x = element_text(size = 9),
        legend.position = "None") 

snow_eda =
  finaldat %>% 
  mutate(snow_ctg = fct_relevel(snow_ctg, c("no_snow", "low", "high"))) %>%   group_by(date, snow_ctg) %>% 
  summarise(mean_resp_time = mean(response_time)) %>% 
  ggplot(aes(x = snow_ctg, y = mean_resp_time)) +
  geom_violin(aes(fill = snow_ctg), alpha = .3) +
  stat_summary(fun.y = mean, geom = "point", size = 2, color = "blue") +
  labs(
    title = "Snowy conditions",
    y = "",
    x = " "
  ) +
  scale_x_discrete(labels = c("0(mm)", "0-50(mm)", "50(mm)+")) +
  viridis::scale_fill_viridis(
    name = "Snow",
    discrete = TRUE) +
  theme(plot.title = element_text(size = 12),
        axis.title.y = element_text(size = 9),
        axis.text.x = element_text(size = 8),
        legend.position = "None") 

prcp_snow = prcp_eda + snow_eda 
ggsave("prcp_snow.png", plot = prcp_snow)
```

2. Season
```{r}
season_eda =
finaldat %>% 
  mutate(season = fct_relevel(season, c("Spring", "Summer", "Fall", "Winter"))) %>% 
  group_by(date, season) %>% 
  summarise(mean_resp_time = mean(response_time)) %>% 
  ggplot(aes(x = season, y = mean_resp_time)) +
  geom_violin(aes(fill = season), alpha = .3) +
  stat_summary(fun.y = mean, geom = "point", size = 2, color = "blue") +
  labs(
    y = "Mean response time (min)",
    x = " "
  ) +
  viridis::scale_fill_viridis(
    name = "season",
    discrete = TRUE) +
  theme(plot.title = element_text(size = 13),
        axis.title.y = element_text(size = 10),
        axis.text.x = element_text(size = 9),
        legend.position = "None") 

ggsave("season.png", plot = season_eda)
```

3. Hour
```{r}
hour_eda =
finaldat %>%
  group_by(hour, season) %>% 
  ggplot(aes(x = hour, y = response_time, color = season)) + 
  geom_smooth(se = FALSE) +
  scale_x_continuous(breaks = c(6, 12, 18),
                     labels = c("6am", "12pm", "18pm")) +
  geom_vline(xintercept = c(6, 12, 18), color = "darkred") +
  labs(
    x = " ", 
    y = "Mean response time (min)"
    ) +
   viridis::scale_color_viridis(
    name = "Season",
    discrete = TRUE)
  theme(plot.title = element_text(size = 13),
        axis.title.y = element_text(size = 10),
        axis.text.x = element_text(size = 12),
        legend.position = "None") 

ggsave("hour.png", plot = hour_eda)
```

Accordingly, based on medical research, using a fact that 8min is a critical point, we categorized response time into binary outcome as less than 8min and over 8min.   

#### Step 3-3:Logistic regression
```{r}
fit_logistic =
  glm(over_8min ~ season + hour_of_day + snow_ctg + prcp_ctg, 
      family = binomial(), data = finaldat)

summary(fit_logistic)

fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         lower_CI_OR = exp(estimate - 1.96*std.error),
         upper_CI_OR = exp(estimate + 1.96*std.error)) %>% 
  select(term, OR, lower_CI_OR, upper_CI_OR) %>% 
  mutate(term = c("intercept", "Fall", "Summer", "Winter", "Afternoon", "Dawn", "Morning", "snow 50+", "snow 50-", "prcp 25+", "prcp 25-")) %>%   knitr::kable(digits = 3, "html") %>% kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))


OR_total_df = 
fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         lower_CI_OR = exp(estimate - 1.96*std.error),
         upper_CI_OR = exp(estimate + 1.96*std.error)) %>% 
  select(term, OR, lower_CI_OR, upper_CI_OR) %>%
  as.tibble() %>% 
  mutate(ctg = c("intercept", 
                 "Season", "Season", "Season", 
                 "Hour of the day", "Hour of the day", "Hour of the day",
                 "Snow", "Snow",
                 "Rain", "Rain"),
         sub_ctg_chr = c("intercept",
                     "Fall", "Summer", "Winter",
                     "Afternoon", "Dawn", "Morning",
                     "50(mm)+", "0-50(mm)",
                     "25(mm)+", "0-25(mm)"),
         sub_ctg = c("1", "2", "1", "3", "8", "6", "7", "5", "4", "5", "4")) %>%   
  filter(ctg != "intercept")  

adj = .2 # This is used in position_nudge to move the dots

OR =
ggplot(OR_total_df, aes(x = OR, y = ctg, color = sub_ctg, 
                        label = sub_ctg_chr)) +
  geom_vline(aes(xintercept = 1), size = 1, linetype = "dashed") +
  geom_vline(aes(xintercept = 1.5), size = .6, linetype = "dashed") +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "1"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50", 
                 position = position_nudge(y = adj)) +
  geom_text(data = filter(OR_total_df, sub_ctg == "1"),
            aes(label = sub_ctg_chr), size = 6, colour = "seagreen4", 
            nudge_x = -.1, nudge_y = +.2, check_overlap = TRUE) +
  geom_point(data = filter(OR_total_df, sub_ctg == "1"), 
             size = 6, color = "seagreen4",
             position = position_nudge(y = adj)) +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "2"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50") +
  geom_text(data = filter(OR_total_df, sub_ctg == "2"),
            aes(label = sub_ctg_chr), size = 6, colour = "indianred4", 
            nudge_x = -.1, nudge_y = 0, check_overlap = TRUE) +
  geom_point(data = filter(OR_total_df, sub_ctg == "2"), 
             size = 6, color = "indianred4") +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "3"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50", position = position_nudge(y = -adj)) +
  geom_text(data = filter(OR_total_df, sub_ctg == "3"),
            aes(label = sub_ctg_chr), size = 6, colour = "lavenderblush4", 
            nudge_x = -.1, nudge_y = -.2, check_overlap = TRUE) +  
  geom_point(data = filter(OR_total_df, sub_ctg == "3"), 
             size = 6, color = "lavenderblush4",
             position = position_nudge(y = -adj)) +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "4"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50", position = position_nudge(y = +.1)) +
  geom_text(data = filter(OR_total_df, sub_ctg == "4"),
            aes(label = sub_ctg_chr), size = 6, colour = "skyblue2", 
            nudge_x = -.15, nudge_y = +.1, check_overlap = TRUE) +
  geom_point(data = filter(OR_total_df, sub_ctg == "4"), 
             size = 6, color = "skyblue2",
             position = position_nudge(y = +.1)) +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "5"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50", position = position_nudge(y = -.1)) +
  geom_text(data = filter(OR_total_df, sub_ctg == "5"),
            aes(label = sub_ctg_chr), size = 6, colour = "skyblue4", 
            nudge_x = -.16, nudge_y = -.1) +
  geom_point(data = filter(OR_total_df, sub_ctg == "5"), 
             size = 6, color = "skyblue4", 
             position = position_nudge(y = -.1)) +
 geom_errorbarh(data = filter(OR_total_df, sub_ctg == "6"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50", 
                 position = position_nudge(y = adj)) +
  geom_text(data = filter(OR_total_df, sub_ctg == "6"),
            aes(label = sub_ctg_chr), size = 6, colour = "seagreen4", 
            nudge_x = -.14, nudge_y = +.2, check_overlap = TRUE) +
  geom_point(data = filter(OR_total_df, sub_ctg == "6"), 
             size = 6, color = "seagreen4",
             position = position_nudge(y = adj)) +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "7"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50") +
  geom_text(data = filter(OR_total_df, sub_ctg == "7"),
            aes(label = sub_ctg_chr), size = 6, colour = "indianred4", 
            nudge_x = -.13, nudge_y = 0, check_overlap = TRUE) +
  geom_point(data = filter(OR_total_df, sub_ctg == "7"), 
             size = 6, color = "indianred4") +
  geom_errorbarh(data = filter(OR_total_df, sub_ctg == "8"), 
                 aes(xmax = upper_CI_OR, xmin = lower_CI_OR), 
                 size = .5, height = .1, 
                 color = "gray50", position = position_nudge(y = -adj)) +
  geom_text(data = filter(OR_total_df, sub_ctg == "8"),
            aes(label = sub_ctg_chr), size = 6, colour = "lavenderblush4", 
            nudge_x = -.13, nudge_y = -.2, check_overlap = TRUE) +  
  geom_point(data = filter(OR_total_df, sub_ctg == "8"), 
             size = 6, color = "lavenderblush4",
             position = position_nudge(y = -adj)) +
  scale_x_continuous(breaks = c(1, 1.5),
                     limits = c(.7, 1.8)) +
  labs(x = "Odds Ratio",
       y = " ") +
  theme_bw() +
  theme(panel.grid.minor = element_blank(),
        axis.title.x = element_text(size = 16),
        axis.text.x = element_text(size = 16),
        axis.text.y = element_text(size = 20),
        legend.position = "None") 

ggsave("OR.png", plot = OR, width = 45, height = 25, units = "cm")
```

Based on EDA, to get statistical analysis, we fit logistic regression and results are followings: 
- Snow: As expected from EDA, compared to no snow conditions, odds of over 8min response time is increased 24% by 0~50mm snow and 47% by over 50mm snow.
- Season: Compared to Spring, Summer does not affect odds of over 8min response time but odds is increased in Fall by 6% and in Winter by 7%.
- Rain: Statistically significant result was not obtained from rain variable and it matches the result of EDA.
- Hour of the day: In reference to night, odds of over 8min response time is increased at dawn by 26%, in the morning by 37% and in the afternoon by 35%.

### Discussion: 
What were your findings? Are they what you expect? What insights into the data can you make?